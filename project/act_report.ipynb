{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Wrangling and Analyze Data\n",
    "\n",
    "**Udacity Data Analyst 4th project**<br>\n",
    "Hitoshi Kumagai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset what I  wrangled (and analyzing and visualizing) is the tweet archive of Twitter user @dog_rates(https://twitter.com/dog_rates), also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc.Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.This project includes steps and detail is below.<br>\n",
    "**Steps**\n",
    "- Data wrangling:Gathering data, Assessing data then Cleaning data.\n",
    "- Storing data, analyzing data and visulalizing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df_archive**\n",
    ">Since the data in CSV file format was provided, the data was used as a data frame for Pandas.The file name is twitter-archive-enhanced.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df_image**\n",
    ">The data in TSV file format was obtained from the url at the end of the sentence.The file name is image_predictions.tsv The retrieved data was used as a data frame for Pandas.\n",
    "\n",
    "URL\n",
    ">https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df_json**\n",
    ">Each tweet's retweet count and favorite (\"like\") count. Using the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. Each tweet's JSON data should be written to its own line. Then read this .txt file line by line into a pandas DataFrame with (at minimum) tweet ID, retweet count, and favorite count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "##### df_archive\n",
    "1. 5 column with Null value <br>\n",
    "2. Float datatype is uesd in ID for 5column  <br>\n",
    "3. Text column  Contains \"&\"\"amp;\" in text column<br>\n",
    "4. expanded_urls contains No image<br>\n",
    "5. Name column dog name is not correct from \"a\", \"the\", etc.<br>\n",
    "6. Name column dog name Missing value seems to be \"None\"<br>\n",
    "7. rating_numerator has outlier from stocastic data and plot<br>\n",
    "8. rating_denominator has outlier from stocastic data and plot<br>\n",
    "\n",
    "##### df_image\n",
    "1. Duplicated jpg_url.\n",
    "2. In p1,p2,p3, unnecessary character strings are included in the character information (e.g. - _) <br>\n",
    "\n",
    "##### df_json\n",
    "1. Duplicated ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**df_archive**\n",
    "1. Remove all columns with missing values.<br>\n",
    "2. Drop 5 column having Null value.<br>\n",
    "3. Delete & amp; from text column.<br>\n",
    "4. Extract only columns that contain unique url.<br>\n",
    "5. Replace incorrect dog name to NaN<.<br>\n",
    "6. Replace the word None with NaN**<br>\n",
    "7. Drop lines with more than 10 numbers in rating_numerator column.<br>\n",
    "8. Drop lines with more than 10 numbers in rating_numerator column<br>\n",
    "9. Drop duplicated jpg_url<br>\n",
    "\n",
    "**df_image**\n",
    "1. Delete \"-\" and \"_\"  from p1,p2,p3 column\n",
    "\n",
    "**df_json**\n",
    "1. Delete duplicated row in ID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness issue\n",
    "1. Merge the tables using the same information as keys in the three tables.\n",
    "1. Consolidate four lines of information into one line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
